# ğŸ§  Topic Modeling on News â€” BBC Dataset

An interactive **topic modeling app** built with **Streamlit**.  
It discovers hidden themes in news articles using:

- **NMF (Nonâ€‘negative Matrix Factorization)** â€” *recommended on this dataset*
- **LDA (Latent Dirichlet Allocation)** â€” baseline for comparison

**Dataset:** [BBC News Summary (Kaggle)](https://www.kaggle.com/datasets/pariza/bbc-news-summary)  
**Live app:** https://topic-modeling-app-77.streamlit.app/

---

## ğŸ“Œ Features

âœ… Paste text **or upload a `.txt` file**  
âœ… Choose **NMF (recommended)** or **LDA**  
âœ… **Top words** for the predicted topic  
âœ… **Topâ€‘5 topic probabilities** (bar plot)  
âœ… **Dominant category** label per topic (NMF) + **purity** percentage  
âœ… **Similarâ€‘article lookup** (shows training articles closest to your input)  
âœ… Mini **metrics** row (coherence, K) to justify the recommendation  
âœ… Clean, singleâ€‘page Streamlit UI

> NMF is recommended because it achieved **higher c_v coherence** on this dataset in the companion notebook and enables categoryâ€‘aware analytics.

---

## ğŸ“ Files Included / Expected

| File | Required | Description |
|------|:-------:|-------------|
| `app.py` | âœ… | Streamlit UI (this repo) |
| `requirements.txt` | âœ… | App dependencies (Streamlit, scikitâ€‘learn, gensim, etc.) |
| `README.md` | âœ… | This file |
| `tfidf_vectorizer.joblib` | âš ï¸ | Fitted TFâ€‘IDF vectorizer (exported from your notebook) |
| `nmf_model.joblib` | âš ï¸ | Trained NMF model (same run as the vectorizer) |
| `best_lda.model` | âš ï¸ | Trained LDA model (gensim) |
| `dictionary.dict` | âš ï¸ | Gensim dictionary used to train LDA |
| `documents_with_topics.csv` | âš ï¸ | Corpus with `text`, `clean_text`, `true_category`, and assigned `topic` (for similarity lookup) |
| `topic_to_category_nmf.json` | âš ï¸ | Mapping: topic â†’ dominant category + purity (exported in notebook) |
| `model_metrics.json` | âš ï¸ | Small JSON with `{NMF: {K, coherence_c_v}, LDA: {K, coherence_c_v}}` for the UI badge |

> Only `app.py` + `requirements.txt` are needed to **run the app**.  
> The other files are **artifacts exported from the notebook** to enable full functionality (prediction, keywords, similarity, and badges).

---

## ğŸš€ How to Run Locally

1) **Clone** and enter the project
```bash
git clone https://github.com/yourname/topic-modeling-news.git
cd topic-modeling-news
```

2) **(Optional) Create a virtual environment**
```bash
python -m venv venv
# Windows: venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

3) **Install dependencies**
```bash
pip install -r requirements.txt
```

4) **Place model artifacts** (exported from your notebook) in the project root:
```
tfidf_vectorizer.joblib
nmf_model.joblib
best_lda.model
dictionary.dict
documents_with_topics.csv
topic_to_category_nmf.json
model_metrics.json
```

5) **Run the app**
```bash
streamlit run app.py
```

---

## ğŸŒ Deployment (Streamlit Cloud)

- Go to https://streamlit.io/cloud  
- Connect your GitHub repo and pick the branch  
- Set **Main file**: `app.py`  
- Add a **Python version** and **requirements.txt** in app settings  
- Place artifact files in the appâ€™s working directory (e.g., upload them as repo assets)

> First load may take longer while dependencies initialize.

---

## ğŸ§ª Notebook Workflow (what was done)

- **Data Collection**  
  - Download the **BBC News Summary** from Kaggle and load all five categories: `business`, `entertainment`, `politics`, `sport`, `tech`.

- **Preprocessing**  
  - Lowercasing, URL removal, punctuation/digit stripping, token filtering, lemmatization (in the notebook).  
  - Build `clean_text` and `tokens` fields; drop empty rows.

- **Topic Modeling**  
  - **LDA**: build dictionary/corpus; sweep `K` over several values; compute **c_v coherence**; select bestâ€‘`K`.  
  - **NMF**: TFâ€‘IDF features; train `NMF(n_components=K)`; get top words per topic.

- **Evaluation & Visualization**  
  - Coherence vs **K** plot (for LDA).  
  - **pyLDAvis** (LDA), **word clouds** (NMF).  
  - Category Ã— Topic **crosstabs**, stacked bars, rowâ€‘normalized **heatmap**.  
  - Compute **dominant topic per category** and **dominant category per topic**.  
  - Derive **purity** = share of dominant topic within each category.

- **Exports (for the app)**  
  - `tfidf_vectorizer.joblib`, `nmf_model.joblib`  
  - `best_lda.model`, `dictionary.dict`  
  - `documents_with_topics.csv` (text, clean_text, true_category, topic)  
  - `topic_to_category_nmf.json` (topic â†’ dominant_category, purity)  
  - `model_metrics.json` with coherence and K for both models

**Key takeaways:**  
- On this dataset, **NMF** achieved **higher coherence** and offers categoryâ€‘aware analytics and similarâ€‘article lookup in the UI.  
- **LDA** remains a solid baseline and is helpful for interactive exploration via pyLDAvis and topâ€‘word lists.

---

## ğŸ§¯ Troubleshooting

- **â€œVectorizer is NOT fitted (missing `idf_`)â€**  
  Reâ€‘export `tfidf_vectorizer.joblib` **after** calling `vect.fit_transform(...)` in the notebook.

- **â€œVectorizer/NMF dimension mismatchâ€**  
  Reâ€‘export **both** `tfidf_vectorizer.joblib` and `nmf_model.joblib` from the **same run** (same vocabulary size).

- **â€œdocuments_with_topics.csv not found â€” similarâ€‘article lookup hiddenâ€**  
  Export the CSV from the notebook with columns: `text`, `clean_text`, `true_category`, `topic`.

- **LDA shows no keywords**  
  Ensure `best_lda.model` and `dictionary.dict` come from the **same training**. The app falls back to `get_topic_terms` if `id2word` is missing.

- **Binary incompatibility errors (NumPy/Scikitâ€‘learn)**  
  Use the pinned versions in `requirements.txt`. If issues persist, create a fresh virtual env and reinstall.

---

## ğŸ“ Sample Input (for the text box)

> â€œWith three matches left in the league calendar, the title race tightened again this weekend as the leaders dropped points at homeâ€¦ broadcasters shifted kickoff slots to prime time, and ticket resale prices surged.â€

---

## ğŸ”’ License

MIT â€” feel free to use and adapt with attribution.

---

## ğŸ™Œ Acknowledgments

- Dataset: BBC News Summary (Kaggle)  
- Libraries: Streamlit, scikitâ€‘learn, gensim, matplotlib, pandas, numpy

